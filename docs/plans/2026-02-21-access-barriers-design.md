# v3 Phase 4: Arabic + Chinese + Japanese + Korean Access Barriers — Design Document

> **Date:** 2026-02-21
> **Status:** Approved design, ready for implementation planning
> **Predecessor:** v3 Phase 3 (Semantic Relation Graph, PR #4)

## Goal

Teach the Epistemix engine that not all academic knowledge is reachable via open web search. Some ecosystems (Chinese CNKI, Arabic Al-Manhal, Japanese CiNii, Korean RISS) gate significant portions of scholarly output behind paywalls or firewalls. The engine must:

1. Generate culturally-aware queries in Arabic, Chinese, Japanese, and Korean
2. Recognize when empty results indicate an access barrier rather than absent knowledge
3. Report coverage as two numbers: what we verified + what we estimate exists but cannot reach

## Architecture Overview

Four additions to the codebase:

1. **MA-08 Access Barriers** — A new meta-axiom predicting that some knowledge ecosystems are structurally inaccessible via web search.
2. **Language Ecosystem Registry** — Per-language metadata classifying access tiers, gated databases, and query generation rules.
3. **Localized Query Generator** — Heuristic rules for morphological (Arabic) and phrasal (CJK) query construction, with LLM fallback when a connector is available.
4. **Split Coverage Scoring** — Coverage becomes a `CoverageBreakdown` with `accessible_score` + `estimated_unreachable`, replacing the single float.

---

## Data Structures (models.py)

### AccessTier enum

Classifies how reachable a language's academic ecosystem is via web search.

```python
class AccessTier(Enum):
    OPEN_WEB = "open_web"           # Fully searchable (English, French, German, etc.)
    PARTIAL_ACCESS = "partial_access" # Some gated, some open (Japanese, Korean, Arabic)
    WALLED_GARDEN = "walled_garden"   # Majority behind paywalls/firewalls (Chinese)
```

### LanguageEcosystem dataclass

Per-language metadata for access-barrier reasoning.

```python
@dataclass(frozen=True)
class LanguageEcosystem:
    language: str              # ISO 639-1 code
    access_tier: AccessTier
    gated_databases: tuple[str, ...]  # e.g., ("CNKI", "Wanfang", "VIP")
    estimated_gated_share: float      # 0.0–1.0, fraction behind walls
    query_style: str                  # "keyword", "morphological", "phrasal"
    script: str                       # "latin", "arabic", "cjk", "hangul"
```

### CoverageBreakdown dataclass

Replaces the single coverage float for richer reporting.

```python
@dataclass
class CoverageBreakdown:
    accessible_score: float           # 0–100, what we can verify
    estimated_unreachable: float      # 0–100, what we think exists but can't reach
    barrier_annotations: list[str]    # Human-readable explanations
    gated_expectations_count: int     # How many expectations are behind barriers
    gated_expectations_met: int       # How many of those we partially satisfied

    def to_dict(self) -> dict[str, Any]: ...
```

### New GapType value

```python
ACCESS_BARRIER = "access_barrier"
```

For anomalies generated by MA-08 expectations.

---

## Language Ecosystem Registry (knowledge.py)

A new `LANGUAGE_ECOSYSTEMS` dict keyed by ISO 639-1 code:

| Language | Access Tier | Gated Databases | Est. Gated Share | Query Style | Script |
|----------|-------------|-----------------|------------------|-------------|--------|
| `zh` | `WALLED_GARDEN` | CNKI, Wanfang, VIP, CQVIP | 0.70 | `phrasal` | `cjk` |
| `ar` | `PARTIAL_ACCESS` | Al-Manhal, E-Marefa, Dar Al Mandumah | 0.35 | `morphological` | `arabic` |
| `ja` | `PARTIAL_ACCESS` | CiNii, J-STAGE, NDL Digital | 0.40 | `phrasal` | `cjk` |
| `ko` | `PARTIAL_ACCESS` | RISS, KCI, DBpia | 0.35 | `phrasal` | `hangul` |

Languages not in this dict default to `OPEN_WEB` / `keyword` / `latin`.

### New country entries in GEOGRAPHIC_LINGUISTIC

- **China**: primary_languages `["zh", "en"]`, foreign_traditions for Japanese/Korean scholarly interest
- **Japan**: primary_languages `["ja", "en"]`
- **South Korea**: primary_languages `["ko", "en"]`
- **Saudi Arabia**: primary_languages `["ar", "en"]`
- **Egypt**: enriched with Arabic transliteration maps

### Cross-language strategies

A `CROSS_LANGUAGE_STRATEGIES` dict mapping walled-garden languages to alternative search approaches:

```python
CROSS_LANGUAGE_STRATEGIES = {
    "zh": [
        ("en", "Chinese research on {topic}"),
        ("ja", "{topic} 中国の研究"),
    ],
    "ar": [
        ("en", "Arabic-language research on {topic}"),
        ("fr", "recherche arabophone sur {topic}"),
    ],
    "ja": [
        ("en", "Japanese research on {topic}"),
    ],
    "ko": [
        ("en", "Korean research on {topic}"),
    ],
}
```

Used by the negative-postulate reformulation loop to avoid retrying queries in a language whose results are behind a wall.

---

## Meta-Axiom MA-08 (meta_axioms.py)

```python
MA_08_ACCESS = MetaAxiom(
    id="MA-08",
    name="Access Barriers",
    description=(
        "Some knowledge ecosystems are structurally inaccessible via "
        "open web search. Walled-garden databases (CNKI, Al-Manhal, etc.) "
        "contain academic literature that cannot be retrieved or verified "
        "through standard search APIs. An audit that ignores these barriers "
        "overstates its coverage."
    ),
    postulate_templates=(
        "Academic literature on {topic} exists behind gated databases in {country}",
        "Web search alone cannot verify {topic} research in walled-garden ecosystems",
        "Coverage of {topic} is structurally incomplete for non-open-web languages",
    ),
)
```

Added to `META_AXIOMS` tuple (now 8 axioms) and `META_AXIOM_BY_ID`.

### How MA-08 differs from MA-01 through MA-07

The existing 7 axioms predict knowledge that *should* exist and we go look for it. MA-08 predicts knowledge that *should* exist but we *cannot* look for it. This inversion means:

- MA-08 expectations are **never satisfiable via web search alone**
- They can be partially satisfied by cross-language proxy searches (English papers *about* Chinese research)
- They can be fully satisfied only by BYOK access to gated databases or manual user confirmation
- Unsatisfied MA-08 expectations **do not penalize** the `accessible_score` — they populate `estimated_unreachable` instead

---

## Localized Query Generation (query_localization.py)

New module at `src/epistemix/query_localization.py`. Zero external dependencies.

### Core function

```python
def localize_query(topic: str, language: str, discipline: str) -> list[str]
```

Returns a list of culturally-aware query strings.

### Arabic (`morphological` style)

- Extract key content words from the English topic
- For each word, generate triliteral root variants using a built-in `ARABIC_TERM_MAP` (e.g., "excavation" → "حفريات", "تنقيب", "حفر")
- Generate queries: root form + discipline term + country
- `ARABIC_ACADEMIC_TERMS` maps discipline names → Arabic (e.g., "archaeology" → "علم الآثار", "virology" → "علم الفيروسات")
- Include Modern Standard Arabic terms; no dialectal variants in v1

### Chinese (`phrasal` style, `cjk` script)

- No spaces — concatenate terms into natural compounds
- `CHINESE_ACADEMIC_TERMS` maps English → Simplified Chinese (e.g., "archaeology" → "考古学", "excavation" → "发掘", "virus" → "病毒")
- Generate 2-4 character compounds: topic term + discipline term + "研究" (research)
- Include Traditional Chinese variants for Taiwan/Hong Kong sources

### Japanese (`phrasal` style, `cjk` script)

- Kanji for Sino-Japanese terms, katakana for foreign loanwords
- `JAPANESE_ACADEMIC_TERMS` dict (e.g., "archaeology" → "考古学", "virus" → "ウイルス")
- Append "研究" (research) or "論文" (paper)

### Korean (`phrasal` style, `hangul` script)

- `KOREAN_ACADEMIC_TERMS` dict (e.g., "archaeology" → "고고학", "virus" → "바이러스")
- Append "연구" (research) or "논문" (paper)

### LLM fallback

```python
def localize_query_via_llm(
    topic: str, language: str, discipline: str, connector
) -> list[str]
```

Asks the connector to generate 3-5 culturally appropriate academic search queries. Called by `MultilingualQueryGenerator` when a connector is available and `query_style != "keyword"`.

---

## Engine Integration (core.py + connector.py)

### MultilingualQueryGenerator changes

- `generate_initial_queries(connector=None)` — for languages with a `LanguageEcosystem` entry, calls `localize_query()` instead of `_transliterate()`. When connector is provided and `query_style != "keyword"`, additionally calls `localize_query_via_llm()` to supplement heuristic queries.
- Gap-filling queries for Arabic/CJK also route through `localize_query()`.

### DynamicInferenceEngine changes

- `derive()` gains a new sub-method `_access_barriers(cycle)`.
- For each language in the country's `primary_languages` that has `access_tier != OPEN_WEB`, it generates expectations:
  - "Chinese academic sources on {topic} behind CNKI flagged as structurally unreachable" (severity: MEDIUM)
- These expectations have `gap_type = GapType.ACCESS_BARRIER`.

### Coverage calculation changes

- `calculate_coverage(expectations, anomalies) -> CoverageBreakdown`
- Partitions expectations: `ACCESS_BARRIER` vs everything else
- `accessible_score` computed from non-barrier expectations (same formula as today)
- `estimated_unreachable` computed from barrier expectations weighted by `estimated_gated_share`
- `CycleSnapshot.coverage_score` stores `accessible_score` — backward compatible
- Full `CoverageBreakdown` available in `to_dict()` output

### NegativePostulate enrichment

When a query in a walled-garden or partial-access language returns zero results:

1. Engine checks `LANGUAGE_ECOSYSTEMS` for that language
2. If `access_tier != OPEN_WEB`:
   - `possible_reason = "access_barrier"`
   - `reformulation` = cross-language proxy from `CROSS_LANGUAGE_STRATEGIES` (e.g., English query about Chinese research)
   - **Does not retry** in the same walled-garden language next cycle
3. If `access_tier == OPEN_WEB`:
   - Existing logic (wrong_terminology, genuinely_absent, etc.)

### Connector changes

New abstract method on `BaseConnector`:

```python
def generate_localized_queries(
    self, topic: str, language: str, discipline: str
) -> list[str]
```

- `MockConnector`: returns pre-configured query lists per language (via `register_localized_queries()`)
- `ClaudeConnector`: prompts the LLM to generate culturally appropriate queries

---

## Test Strategy

### Amphipolis (existing, untouched)

All 171 existing tests pass without modification. `CycleSnapshot.coverage_score` still stores a float (the `accessible_score`). No Amphipolis fixtures change.

### SARS-CoV-2 (new scenario)

Topic: "SARS-CoV-2 origins", Country: "China", Discipline: "virology"

Chosen because:
- Strong Chinese research component (Wuhan Institute of Virology)
- Significant Arabic literature (MERS precedent in Middle East)
- Japanese pandemic response research
- Korean CDC publications
- Multi-language coverage is well-documented and verifiable

### New test files

**`test_access_barriers.py`** (~15 tests):
- MA-08 postulate generation for China topic
- LanguageEcosystem lookup and defaults
- CoverageBreakdown split scoring
- Access-barrier negative postulate creation
- Cross-language reformulation strategies
- Expectations partitioning (barrier vs accessible)

**`test_query_localization.py`** (~10 tests):
- Arabic morphological query generation
- Chinese phrasal query generation (simplified + traditional)
- Japanese kanji/katakana query generation
- Korean hangul query generation
- LLM fallback with MockConnector

### Updated test files

- `test_models.py` — AccessTier, LanguageEcosystem, CoverageBreakdown serialization (~3-4 tests)
- `test_core.py` — CoverageBreakdown backward compatibility (~2-3 tests)
- `conftest.py` — SARS-CoV-2 mock fixtures

### Estimated total: ~30 new tests (171 → ~201)

---

## Dependency Graph

```
meta_axioms.py ──┐
                 │
models.py ───────┤
                 ├──► semantic_graph.py ────┐
knowledge.py ────┤                          │
                 ├──► disciplines.py ───────┤
                 ├──► content_analysis.py ──┤
                 ├──► query_localization.py ┤  ← NEW
                 │                          │
                 ├──► connector.py          │
                 │       │                  │
                 │       ▼                  ▼
                 └──► core.py ──────► multi_agent.py
                                            │
                                            ▼
                                         run.py
```

`query_localization.py` imports from `models.py` and `knowledge.py` only. Nothing imports from it except `core.py`.

---

## Files Summary

### Create (3 files)

| File | Purpose |
|------|---------|
| `src/epistemix/query_localization.py` | Heuristic + LLM query generation for Arabic, Chinese, Japanese, Korean |
| `tests/test_query_localization.py` | ~10 tests for localized query heuristics |
| `tests/test_access_barriers.py` | ~15 tests for MA-08, ecosystems, coverage breakdown |

### Modify (7 files)

| File | Changes |
|------|---------|
| `src/epistemix/models.py` | Add `AccessTier`, `LanguageEcosystem`, `CoverageBreakdown`, `ACCESS_BARRIER` gap type |
| `src/epistemix/knowledge.py` | Add `LANGUAGE_ECOSYSTEMS`, `CROSS_LANGUAGE_STRATEGIES`, new country entries |
| `src/epistemix/meta_axioms.py` | Add `MA_08_ACCESS`, update `META_AXIOMS` tuple (7 → 8) |
| `src/epistemix/connector.py` | Add `generate_localized_queries()` to all connector classes |
| `src/epistemix/core.py` | Wire localization into query gen, add `_access_barriers()`, update coverage to `CoverageBreakdown` |
| `tests/conftest.py` | Add SARS-CoV-2 fixtures |
| `tests/test_models.py` | Tests for new data structures |

### Untouched

`semantic_graph.py`, `disciplines.py`, `content_analysis.py`, `multi_agent.py`, `run.py`
